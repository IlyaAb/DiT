{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG2LBE_1Zu_v"
      },
      "source": [
        "# Scalable Diffusion Models with Transformer (DiT)\n",
        "\n",
        "This notebook samples from pre-trained DiT models. DiTs are class-conditional latent diffusion models trained on ImageNet that use transformers in place of U-Nets as the DDPM backbone. DiT outperforms all prior diffusion models on the ImageNet benchmarks.\n",
        "\n",
        "[Project Page](https://www.wpeebles.com/DiT) | [HuggingFace Space](https://huggingface.co/spaces/wpeebles/DiT) | [Paper](http://arxiv.org/abs/2212.09748) | [GitHub](github.com/facebookresearch/DiT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hACpcXmcZu_y"
      },
      "source": [
        "# 1. Setup / Установка нужных библиотек\n",
        "\n",
        "We recommend using GPUs (Runtime > Change runtime type > Hardware accelerator > GPU)\n",
        "\n",
        "Рекомендуется использовать GPU, в противном случае все будет ужасно медленным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6HsJYaMZu_y"
      },
      "outputs": [],
      "source": [
        "# the requirements file contains a list of libraries that I use on my home PC\n",
        "# в файле requirements представлен список библиотек, который используя я у себя на домашнем пк\n",
        "\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk16lVXxZu_z"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/IlyaAb/DiT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bas5LSkZu_0"
      },
      "outputs": [],
      "source": [
        "#for collab\n",
        "\n",
        "!pip install diffusers==0.18.2\n",
        "!pip install accelerate\n",
        "!pip install torchinfo\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG-DYoKpZu_2"
      },
      "outputs": [],
      "source": [
        "#most of these libraries are needed only in case of experiments in a laptop, all important steps are done by accessing the .py files through the terminal, where the necessary imports are implemented\n",
        "#большинство из этих библиотек нужны только в случае экспериментов в ноутбуке, все важные шаги осуществляются путем обращения к .py файлам через терминал, где нужные импорты реалзиованы\n",
        "\n",
        "import DiT, os\n",
        "os.chdir(r'DiT')\n",
        "\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "import torchinfo\n",
        "from diffusion import create_diffusion\n",
        "from diffusers.models import AutoencoderKL\n",
        "from download import find_model\n",
        "from models import DiT_XL_2\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "torch.set_grad_enabled(False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if device == \"cpu\":\n",
        "    print(\"GPU not found. Using CPU instead.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B09jzw1cZu_4"
      },
      "outputs": [],
      "source": [
        "#show model arch. how much params\n",
        "\n",
        "image_size = 256\n",
        "latent_size = int(image_size) // 8\n",
        "model = DiT_XL_2(input_size=latent_size)\n",
        "\n",
        "torchinfo.summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qw8zP_-Zu_6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6RfWRzMZu_6"
      },
      "source": [
        "# 2. Loading the dataset. Here is an example with an already existing drone dataset from /\n",
        "# Загрузка датасета. Здесь представлен пример с уже имеющимся датасетом дронов из\n",
        "\n",
        "https://www.kaggle.com/datasets/dasmehdixtr/drone-dataset-uav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52oU0Zf9Zu_7"
      },
      "outputs": [],
      "source": [
        "#saving only pictures in a separate folder, when creating a folder, you need to remember about the hierarchy, each class has a separate folder\n",
        "#сохранение в отдельную папку только картинок, при создании папки нужно помнить об иерархии, каждому классу отдельная папка\n",
        "source = '...drone_dataset_yolo\\dataset_txt'\n",
        "for i in os.listdir(source):\n",
        "    if 'jpg' in i:\n",
        "        shutil.copy(f'{source}\\{i}', '...\\drones_for_dit\\drones')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1WxvEPfZu_7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rkPUorjZu_8"
      },
      "source": [
        "# 3. Extracting features from dataset /\n",
        "# Извлечение фич из данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFjYTjPjZu_8"
      },
      "source": [
        "Создание фич с помощью энкодера из AutoencoderKL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrfRslLyZu_8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgrk_7xpZu_9"
      },
      "outputs": [],
      "source": [
        "#vae arch\n",
        "vae_model = \"stabilityai/sd-vae-ft-ema\"\n",
        "vae = AutoencoderKL.from_pretrained(vae_model) #.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N98g-_lmZu_9"
      },
      "outputs": [],
      "source": [
        "# this part of the model is not trained, first the encoder is taken to extract the features, and at the end the decoder is taken to get the pictures again\n",
        "# это часть модели не обучается, сначалаб берется жнкодер для извленчение фич, а в конце берется декодер, чтобы снова получить картинки\n",
        "torchinfo.summary(vae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_0ydI-_Zu_-"
      },
      "outputs": [],
      "source": [
        "!torchrun \\\n",
        "--nnodes=1 \\\n",
        "--nproc_per_node=1 extract_features.py \\\n",
        "--data-path ...\\drones_for_dit \\\n",
        "--features-path ...\\dit_features2 \\\n",
        "--image-size 256 \\\n",
        "--global-batch-size 256 \\\n",
        "--global-seed 0 \\\n",
        "--vae ema \\\n",
        "--num-workers 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwFcSajnZu_-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_zb2s8hZu_-"
      },
      "source": [
        "# 4.Training the model on the received features from the encoder\n",
        "# Тренировка модели на полученных фичах из энкодера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uwgPjJ-mlRZ"
      },
      "outputs": [],
      "source": [
        "#for finetune must go to train.py and uncomment string which change y_embedder dimension in loading weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS0kDclnZu__"
      },
      "outputs": [],
      "source": [
        "!accelerate launch \\\n",
        "--mixed_precision fp16 train.py \\\n",
        "--feature-path ...\\dit_features \\\n",
        "--results-dir ...\\dit_weights \\\n",
        "--model DiT-S/2 \\\n",
        "--image-size 256 \\\n",
        "--num-classes 1 \\\n",
        "--epochs=10 \\\n",
        "--global-batch-size=16 \\\n",
        "--global-seed 0 \\\n",
        "--num-workers 0 \\\n",
        "--log-every=25 \\\n",
        "--ckpt-every=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RTttC2rZu__"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLjG8CdRZu__"
      },
      "source": [
        "# 5.Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBRoKqAHZvAA"
      },
      "outputs": [],
      "source": [
        "#sampling several imgs from pretrained XL model\n",
        "\n",
        "!python sample.py \\\n",
        "--model DiT-XL/2 \\\n",
        "--vae ema \\\n",
        "--image-size=256 \\\n",
        "--num-classes=1000 \\\n",
        "--cfg-scale 8 \\\n",
        "--num-sampling-steps=10 \\\n",
        "--seed 0 \\\n",
        "--save-result-path /content/ \\\n",
        "--list-classes \"895, 0, 42\" #define number and labels of classes /определяет кол-во, и классы сэмплированных изображений\n",
        "#--ckpt ...\\DiT-XL-2-256x256.pt #если здесь не указывать ничего то будет автоматически скачаны веса XL модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-s-CbwVZvAA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5WdQ1IZk1JQ"
      },
      "outputs": [],
      "source": [
        "#link for pretrained DiT_S model for generating drones imgs (not good qual)\n",
        "# https://drive.google.com/file/d/1tW5hSCysitZ7tKOj5Ko9k4PdX1Pk6uZ7/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ7ZMlSslwGR"
      },
      "outputs": [],
      "source": [
        "#example of sampling from downloaded weigths\n",
        "\n",
        "!python sample.py \\\n",
        "--model DiT-S/2 \\\n",
        "--vae ema \\\n",
        "--image-size=256 \\\n",
        "--num-classes=1 \\\n",
        "--cfg-scale 8 \\\n",
        "--num-sampling-steps=110 \\\n",
        "--seed 0 \\\n",
        "--save-result-path /content/ \\\n",
        "--list-classes \"0, 0, 0\" \\\n",
        "#define number and labels of classes (there are only one classes (drones))/определяет кол-во, и классы сэмплированных изображений\n",
        "--ckpt /content/dit_s_drone_pretrain_35000 #если здесь не указывать ничего то будет автоматически скачаны веса XL модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMbgqkqIk1G1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YTyU6MuoZHy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojwp64r8oZFH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REPVAolLZvAA"
      },
      "outputs": [],
      "source": [
        "#sampling many imgs, very useful if u have more than one gpu, generate npz file for FID metric\n",
        "\n",
        "!torchrun sample_ddp.py \\\n",
        "--model DiT-XL/2 \\\n",
        "--vae ema \\\n",
        "--sample-dir /path/to/generated/data \\\n",
        "--per-proc-batch-size 32 \\\n",
        "--num-fid-sample 400 \\\n",
        "--image-size 265 \\\n",
        "--num-classes 1 \\\n",
        "--cfg-scale 7 \\\n",
        "--num-sampling-steps 250 \\\n",
        "--global-seed 42 \\\n",
        "--ckpt /path/to/your/trained/models/weights"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
